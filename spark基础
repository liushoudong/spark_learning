Spark

RDD 弹性分布式数据集
  RDD是Spark对于分布式数据的统一抽象，它定义了一系列分布式数据的基本属性与处理方法
  RDD 是一种抽象，它所囊括的是分布式计算环境中的分布式数据集
  RDD 代表的数据集是跨进程、跨节点的，它的“活动范围”是整个集群
  RDD 中承载数据的基本单元是数据分片。在分布式计算环境中，一份完整的数据集，会按照某种规则切割成多份数据分片。这些数据分片被均匀地分发给集群内不同的计算节点和执行进程，从而实现分布式并行计算
  
  4大属性：
    partitions：数据分片
    partitioner：分片切割规则
    dependencies：RDD依赖
    compute：转换函数
  
  在数据形态的转换过程中，每个 RDD 都会通过 dependencies 属性来记录它所依赖的前一个、或是多个 RDD，简称“父 RDD”。
  与此同时，RDD 使用 compute 属性，来记录从父 RDD 到当前 RDD 的转换操作。
  
  RDD 到 RDD 之间的转换，本质上是数据形态上的转换（Transformations）
  在RDD的编程模型中一共有两种算子：Transformations类算子和Actions类算子。开发者需要用Transformations类算子，定义并描述数据形态的转换过程，然后调用Actions类算子，
  将计算结果收集起来、或是物化到物理磁盘
  
  Spark 在运行时的计算被划分为两个环节。
  基于不用数据形态之间的转换，构建计算流图（DAG，Directed Acyclic Graph）；
  通过 Actions 类算子，以回溯的方式去触发执行这个计算流图。
  
  创建RDD：
    在Spark中，创建RDD的典型方式有两种：
      通过 SparkContext.parallelize 在内部数据之上创建 RDD；
      通过 SparkContext.textFile 等 API 从外部数据创建 RDD。
      

常用算子

  类型：Transformations 
  适用范围：任意RDD 
  算子用途：RDD内数据转换
  算子集合：map、mapPartitions、flatMap、filter、mapPartitionsWithIndex
  
  map：以元素为粒度的数据转换
    用法：给定映射函数f，map(f)以元素为粒度对RDD做数据转换。其中f可以是带有明确签名的带名函数，也可以是匿名函数，它的形参类型必须与RDD的元素类型保持一致，而输出类型则任由开发者自行决定
      
  mapPartitions:以数据分区为粒度的数据转换
    用法：以数据分区为粒度，使用映射函数f对RDD进行数据转换
  
  flatMap：从元素到集合、再从集合到元素
    对于给定映射函数 f，flatMap(f) 以元素为粒度，对 RDD 进行数据转换
    
  filter
